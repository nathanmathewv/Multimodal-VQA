{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b112775",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d730ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbd26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key = api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf545a5",
   "metadata": {},
   "source": [
    "### VQA Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c7aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARVESH_START = 0\n",
    "SARVESH_END = 6800\n",
    "NATHAN_START = 6800\n",
    "NATHAN_END = 13300\n",
    "DIVYAM_START = 13300\n",
    "DIVYAM_END = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ced330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_response(image_path, user_prompt, system_prompt):\n",
    "    # Read the image as binary\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_data = img_file.read()\n",
    "\n",
    "    contents = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                {\"inline_data\": {\"mime_type\": \"image/jpeg\", \"data\": image_data}},\n",
    "                {\"text\": system_prompt+user_prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    model = \"gemini-1.5-flash\"\n",
    "    response = client.models.generate_content(model=model, contents=contents)\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f296863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(data):\n",
    "    vqa_data = {}\n",
    "    vqa_data[\"item_keywords\"] = [kw.get(\"value\", \"\") for kw in data.get(\"item_keywords\", []) if kw.get(\"language_tag\", \"\").startswith('en')]\n",
    "    temp = vqa_data[\"item_keywords\"].copy()\n",
    "    keywords = ['color','product-type']\n",
    "    for i in range(min(5, len(temp))):\n",
    "        keywords.append(temp[i])\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59caeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_response(response):\n",
    "    \"\"\"\n",
    "    Pre-process the response from chat_response.\n",
    "    \n",
    "    Expected format (as a JSON string):\n",
    "    [\n",
    "      [\"Question 1\", \"Answer 1\"],\n",
    "      [\"Question 2\", \"Answer 2\"]\n",
    "    ]\n",
    "    \n",
    "    This function removes extra text if necessary, extracts the JSON portion,\n",
    "    and converts it into a Python list.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    response = response.strip()\n",
    "    start_index = response.find('[')\n",
    "    end_index = response.rfind(']')\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        json_str = response[start_index:end_index+1]\n",
    "        try:\n",
    "            qa_pairs = json.loads(json_str)\n",
    "            return qa_pairs\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"No JSON array found in the response.\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4131bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = pd.read_csv(\"Dataset/metadata/image_data.csv\")\n",
    "# images_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74dce904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file already exists. \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"Dataset/metadata/image_data_with_vqa.csv\"):\n",
    "    images_data['vqa_response'] = None\n",
    "    for index, row in images_data.iterrows():\n",
    "        images_data.at[index, 'vqa_response'] = None\n",
    "    images_data.to_csv(\"Dataset/metadata/image_data_with_vqa.csv\", index=False)\n",
    "else:\n",
    "    print(\"The CSV file already exists. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309ef7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = pd.read_csv(\"Dataset/metadata/image_data_with_vqa.csv\")\n",
    "# images_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "Already generated for this image\n",
      "515SRd7XpuL\n",
      "Total images processed:  1\n",
      "81jPNIa-+1L\n",
      "Total images processed:  2\n",
      "71oFcjO2ZsL\n",
      "Total images processed:  3\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a Visual Question Answering (VQA) dataset generator.\n",
    "Given an image and a list of metadata strings, generate diverse, high-quality question-answer pairs that cover visual recognition, attributes, relationships, metadata, and reasoning.\n",
    "Make sure that the generated questions do not ask for any numerical answers.\n",
    "Design the dataset so that people who are viewing the image are able to answer the questions.\n",
    "Output each pair as a JSON response.\n",
    "\"\"\"\n",
    "count = 0\n",
    "for i in range(SARVESH_START, SARVESH_END):\n",
    "    if not pd.isna(images_data.iloc[i]['vqa_response']):\n",
    "        print(\"Already generated for this image\")\n",
    "        continue\n",
    "    time.sleep(35)\n",
    "    count += 1\n",
    "    image = images_data.iloc[i]['image_path']\n",
    "    image_id = images_data.iloc[i]['image_id']\n",
    "    print(image_id)\n",
    "    \n",
    "    listing = images_data.iloc[i]['listing']\n",
    "    listing = json.loads(listing)\n",
    "    keywords = get_keywords(listing)\n",
    "    user_prompt = f\"\"\"\n",
    "    Image ID: {image_id}\n",
    "    Metadata: {keywords}\n",
    "    Generate 2-3 question-answer pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    response = chat_response(image, user_prompt, system_prompt)\n",
    "    response = preprocess_response(response)\n",
    "    # print(response)\n",
    "    print(\"Total images processed: \", count)\n",
    "    images_data.at[i, 'vqa_response'] = json.dumps(response)\n",
    "    images_data.to_csv(\"Dataset/metadata/image_data_with_vqa.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99937e",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7cd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = pd.read_csv(\"Dataset/metadata/image_data_with_vqa.csv\")\n",
    "images_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ecdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print the vqa_response column for the first 20 rows\n",
    "images_data['vqa_response'].head(22).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and display it\n",
    "img = mpimg.imread(\"Dataset/final_dataset/8ccb5859.jpg\")\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d8fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
